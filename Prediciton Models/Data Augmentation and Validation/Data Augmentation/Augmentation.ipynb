{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112120,
     "status": "ok",
     "timestamp": 1748000608680,
     "user": {
      "displayName": "Souharda Shikhar Biswas",
      "userId": "16305092273022203443"
     },
     "user_tz": -330
    },
    "id": "1eWqe_Pq2Xfa",
    "outputId": "c1c9d93e-e97f-4c49-a6d5-00ba7ef6f670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textattack\n",
      "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Collecting bert-score>=0.3.5 (from textattack)\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from textattack) (0.8.1)\n",
      "Collecting flair (from textattack)\n",
      "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from textattack) (3.18.0)\n",
      "Collecting language-tool-python (from textattack)\n",
      "  Downloading language_tool_python-2.9.3-py3-none-any.whl.metadata (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lemminflect (from textattack)\n",
      "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting lru-dict (from textattack)\n",
      "  Downloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: datasets>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from textattack) (2.14.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from textattack) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from textattack) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from textattack) (1.15.3)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from textattack) (2.6.0+cu124)\n",
      "Collecting terminaltables (from textattack)\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting word2number (from textattack)\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting num2words (from textattack)\n",
      "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from textattack) (10.7.0)\n",
      "Collecting pinyin>=0.4.0 (from textattack)\n",
      "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from textattack) (0.42.1)\n",
      "Collecting OpenHowNet (from textattack)\n",
      "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.5->textattack) (3.10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets>=2.4.0->textattack) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Collecting boto3>=1.20.27 (from flair->textattack)\n",
      "  Downloading boto3-1.38.22-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair->textattack)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair->textattack)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (5.2.0)\n",
      "Collecting langdetect>=1.0.9 (from flair->textattack)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (5.4.0)\n",
      "Collecting mpld3>=0.3 (from flair->textattack)\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair->textattack)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (1.6.1)\n",
      "Collecting segtok>=1.5.11 (from flair->textattack)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (0.9.0)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
      "  Downloading transformer_smaller_training_vocab-0.4.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
      "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack)\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python->textattack) (5.9.5)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python->textattack) (0.10.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->textattack) (8.2.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->textattack) (1.5.0)\n",
      "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting anytree (from OpenHowNet->textattack)\n",
      "  Downloading anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from OpenHowNet->textattack) (75.2.0)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting botocore<1.39.0,>=1.38.22 (from boto3>=1.20.27->flair->textattack)\n",
      "  Downloading botocore-1.38.22-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.20.27->flair->textattack)\n",
      "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.20.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair->textattack) (4.13.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.2.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.6.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair->textattack) (5.29.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (3.0.2)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (1.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.7)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
      "Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.7/445.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading language_tool_python-2.9.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
      "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading boto3-1.38.22-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading anytree-2.13.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.38.22-py3-none-any.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pinyin, word2number, docopt, langdetect, pptree, sqlitedict, wikipedia-api, intervaltree\n",
      "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=bfd3abc71fe011740f7a84d41f15f727aa83c5a09b4d192a50116073c8622a9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/f5/31/ac8c91eccb570a59fe5f1471ad9f11bece8f4fd4be1ab1be25\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=eef133c44d2b75e8151af961ad30899862c72ae8251ae4851ecefcdab217df52\n",
      "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f75540a0884e884681bb08dce337bf80e6d58224558dcf6e874d0ebc5bd8f7fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=c4a1496462169e831cfec18e3be5a19c4c5cc694a830b1bfa92612f4408d6d60\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4609 sha256=85cbced296c7bb4db5fefe1256d069b98733f67b3139301b9186e8fe86af0c03\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/8a/eb/d683aa6d09dc68ebfde2f37566ddc8807837c4415b4fd2b04c\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=0d630ef8aa206e665a22e8752f2e17d8265760a9dc23b12292b6112cf4641705\n",
      "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=def9a9d7192e04f17747807ba3ce5bac8e107990989e289842960dced64d8177\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=c851ae594f563dcb75553c2edaa574cc7544d04e6829a57888ae1db0d71ae2e1\n",
      "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
      "Successfully built pinyin word2number docopt langdetect pptree sqlitedict wikipedia-api intervaltree\n",
      "Installing collected packages: word2number, sqlitedict, pptree, pinyin, docopt, terminaltables, segtok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, num2words, lru-dict, lemminflect, langdetect, jsonlines, jmespath, intervaltree, ftfy, deprecated, conllu, anytree, wikipedia-api, OpenHowNet, nvidia-cusparse-cu12, nvidia-cudnn-cu12, language-tool-python, botocore, bioc, s3transfer, nvidia-cusolver-cu12, mpld3, boto3, pytorch-revgrad, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed OpenHowNet-2.0 anytree-2.13.0 bert-score-0.3.13 bioc-2.1 boto3-1.38.22 botocore-1.38.22 conllu-4.5.3 deprecated-1.2.18 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 language-tool-python-2.9.3 lemminflect-0.2.3 lru-dict-1.3.0 mpld3-0.5.10 num2words-0.5.14 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pinyin-0.4.0 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.13.0 segtok-1.5.11 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.10 transformer-smaller-training-vocab-0.4.1 wikipedia-api-0.8.1 word2number-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textattack transformers sentencepiece pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17332,
     "status": "ok",
     "timestamp": 1748000629896,
     "user": {
      "displayName": "Souharda Shikhar Biswas",
      "userId": "16305092273022203443"
     },
     "user_tz": -330
    },
    "id": "o7yngfCK2m1M",
    "outputId": "8626277f-0b32-4122-d115-3ed27b77d454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29402,
     "status": "ok",
     "timestamp": 1748000673793,
     "user": {
      "displayName": "Souharda Shikhar Biswas",
      "userId": "16305092273022203443"
     },
     "user_tz": -330
    },
    "id": "-Q2Rr1xl4SJF",
    "outputId": "943e582a-ab43-4035-9e8f-93227fdccb83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Updating TextAttack package dependencies.\n",
      "textattack: Downloading NLTK required packages.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package omw to /root/nltk_data...\n",
      "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textattack.augmentation import CLAREAugmenter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1748000681135,
     "user": {
      "displayName": "Souharda Shikhar Biswas",
      "userId": "16305092273022203443"
     },
     "user_tz": -330
    },
    "id": "0-IXfGnZ3jJj",
    "outputId": "b9631f9a-285b-4d20-955a-480fd3ddd549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resuming with 422 augmented rows already present.\n",
      "\n",
      "📊 Remaining classes needing augmentation:\n",
      " → ask more: 225 more\n",
      " → disease manifestations: 40 more\n"
     ]
    }
   ],
   "source": [
    "# === PATHS ===\n",
    "original_path = \"/content/drive/MyDrive/merged_question_intent_dataset.csv\"  # ✅ Your raw input dataset\n",
    "checkpoint_path = \"/content/drive/MyDrive/augmented_backup.csv\"  # ✅ Progress is saved here\n",
    "final_output_path = \"/content/drive/MyDrive/random_augmented_balanced_dataset.csv\"  # ✅ Final merged file\n",
    "\n",
    "# === LOAD DATA ===\n",
    "original_df = pd.read_csv(original_path)\n",
    "\n",
    "# Load or create backup file\n",
    "try:\n",
    "    augmented_df = pd.read_csv(checkpoint_path)\n",
    "    print(f\"✅ Resuming with {len(augmented_df)} augmented rows already present.\")\n",
    "except FileNotFoundError:\n",
    "    augmented_df = pd.DataFrame(columns=[\"text\", \"intent\"])\n",
    "    print(\"⚠️ No backup found. Starting fresh.\")\n",
    "\n",
    "# === COUNT CURRENT SAMPLES PER CLASS ===\n",
    "original_counts = original_df['intent'].value_counts().to_dict()\n",
    "aug_counts = augmented_df['intent'].value_counts().to_dict()\n",
    "\n",
    "# Pick target counts\n",
    "random.seed(42)  # For reproducibility\n",
    "target_counts = {cls: random.randint(1300, 1800) for cls in original_counts.keys()}\n",
    "\n",
    "# Compute what's still needed\n",
    "classes_to_augment = {}\n",
    "for cls, orig_count in original_counts.items():\n",
    "    already_aug = aug_counts.get(cls, 0)\n",
    "    remaining = target_counts[cls] - orig_count - already_aug\n",
    "    if remaining > 0:\n",
    "        classes_to_augment[cls] = remaining\n",
    "\n",
    "if not classes_to_augment:\n",
    "    print(\"🎉 All classes are already fully augmented. Nothing to do.\")\n",
    "else:\n",
    "    print(\"\\n📊 Remaining classes needing augmentation:\")\n",
    "    for cls, count in classes_to_augment.items():\n",
    "        print(f\" → {cls}: {count} more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nwgU7uH4NKf",
    "outputId": "b0c87eab-8398-4d29-c34b-89b2f8a53dca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Augmenting 'ask more' → Need: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 'ask more':  95%|██████████████████████████████████▏ | 214/225 [1:26:15<00:53,  4.82s/it]"
     ]
    }
   ],
   "source": [
    "# === SETUP AUGMENTER ===\n",
    "augmenter = CLAREAugmenter(model=\"roberta-base\", transformations_per_example=1)\n",
    "grouped = original_df.groupby(\"intent\")\n",
    "augmented_rows = augmented_df.values.tolist()\n",
    "\n",
    "# === AUGMENT ONLY WHAT'S MISSING ===\n",
    "for intent, needed in classes_to_augment.items():\n",
    "    print(f\"\\n🔧 Augmenting '{intent}' → Need: {needed}\")\n",
    "    group = grouped.get_group(intent)\n",
    "    texts = group['text'].tolist()\n",
    "    generated = 0\n",
    "\n",
    "    with tqdm(total=needed, desc=f\"Generating '{intent}'\", ncols=100) as pbar:\n",
    "        while generated < needed:\n",
    "            for text in texts:\n",
    "                if generated >= needed:\n",
    "                    break\n",
    "                try:\n",
    "                    aug_texts = augmenter.augment(text)\n",
    "                    if aug_texts:\n",
    "                        augmented_rows.append((aug_texts[0], intent))\n",
    "                        generated += 1\n",
    "                        pbar.update(1)\n",
    "\n",
    "                        # Save progress every 50 augmentations\n",
    "                        if generated % 50 == 0:\n",
    "                            pd.DataFrame(augmented_rows, columns=[\"text\", \"intent\"]).to_csv(checkpoint_path, index=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error on: {e}\")\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oF1-LN2p4uEJ"
   },
   "outputs": [],
   "source": [
    "# === SAVE FINAL MERGED DATA ===\n",
    "aug_df = pd.DataFrame(augmented_rows, columns=[\"text\", \"intent\"])\n",
    "final_df = pd.concat([original_df, aug_df]).sample(frac=1).reset_index(drop=True)\n",
    "final_df.to_csv(final_output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Done! Final dataset saved to:\\n📁 {final_output_path}\")\n",
    "print(f\"📊 Total records: {len(final_df)}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMbc5Uud45Frh61P3+BZMdG",
   "gpuType": "T4",
   "mount_file_id": "1Nc1fba-DWAKZVKqX_8JjyRvpSIxI1AQt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
